{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WDb1ilq8WZ5r"
   },
   "source": [
    "# Fashion MNIST Data Science Challenge: Neural Networks and Deep Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mi1HaLfefo0q"
   },
   "source": [
    "## **Intuition**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T01BhSUXioKW"
   },
   "source": [
    "### Our goal\n",
    "Classify clothes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CjKc-XPe9F5N"
   },
   "source": [
    "![alt text](https://miro.medium.com/max/608/1*3QpK4Vhw0BpbjwijIYFkfQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labels\n",
    "\n",
    "Each training and test example is assigned to one of the following labels:\n",
    "\n",
    "<li>0 T-shirt/top </li>\n",
    "<li>1 Trouser</li>\n",
    "<li>2 Pullover </li>\n",
    "<li>3 Dress </li>\n",
    "<li>4 Coat </li>\n",
    "<li>5 Sandal</li>\n",
    "<li>6 Shirt </li>\n",
    "<li>7 Sneaker </li>\n",
    "<li>8 Bag </li>\n",
    "<li>9 Ankle boot </li>\n",
    "--------------------------\n",
    "\n",
    "Each row is a separate image\n",
    "\n",
    "Column 1 is the class label.\n",
    "Remaining columns are pixel numbers (784 total).\n",
    "Each value is the darkness of the pixel (1 to 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y1Y8vixb7aCw"
   },
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_60sCVqkfs2a"
   },
   "source": [
    "![](http://neuralnetworksanddeeplearning.com/images/tikz12.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pgNC8OyiiStg"
   },
   "source": [
    "### Artificial Neuron\n",
    "Inputs are weighted, summed up, a bias is added and the result is transformed by a nonlinear activation function. \n",
    "![alt text](https://www.researchgate.net/publication/320270458/figure/fig1/AS:551197154254848@1508427050805/Mathematical-model-of-artificial-neuron.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YHg9cuxIsl7Z"
   },
   "source": [
    "### Activation function\n",
    "Squashes the weighted inputs into $[0, 1]$ (i.e. bounds the outputs) and introduces non-linearity to the model, e.g.\n",
    "\n",
    "**Sigmoid function**:\n",
    "\\begin{eqnarray} \n",
    "  \\sigma(z) \\equiv \\frac{1}{1+e^{-z}}\n",
    "  \\end{eqnarray}\n",
    "![alt text](https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/1200px-Logistic-curve.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lkzA-x6pgTNn"
   },
   "source": [
    "### Forward pass\n",
    "Outputs are calculated in a **feed-forward manner**: activated weighted sums are propagated through the network to the output layer.\n",
    "\n",
    "![alt text](https://glassboxmedicine.files.wordpress.com/2019/01/slide2.jpg?w=616)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vQOAfuBSza20"
   },
   "source": [
    "### Backward pass\n",
    "Errors are calculated from the outputs and **backpropagated**: the network improves its predictions (it learns) by updating the weights and biases in each backward pass from the last to the first hidden layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RpybfDFvgcbh"
   },
   "source": [
    "#### Loss function\n",
    "Or cost function; Compares actual with desired outputs of the network and therefore measures the predictive performance of the network. \n",
    "$\\begin{eqnarray} C(w,b) \\equiv\n",
    "  \\frac{1}{2n} \\sum_x \\| y(x) - a\\|^2.\n",
    "\\end{eqnarray}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KfF-eoP9g75d"
   },
   "source": [
    "#### Optimization\n",
    "Improve the networks performance by minimizing the cost w.r.t. the network's parameters w and b: \n",
    "$\\begin{equation}\n",
    "\\begin{aligned} \\min_{w,b} C(w,b) \n",
    "\\end{aligned}\n",
    "\\end{equation}$ <br>\n",
    "Compute partial derivatives $\\partial C / \\partial w$ and $\\partial C / \\partial b$ to identify the slope of the cost function w.r.t. w and b and use **gradient descent** step downwards by updating the parameters:\n",
    "\n",
    "![alt text](http://neuralnetworksanddeeplearning.com/images/valley_with_ball.png)\n",
    "\\begin{eqnarray}\n",
    "  w_k & \\rightarrow & w_k' = w_k-\\eta \\frac{\\partial C}{\\partial w_k} \\\\\n",
    "  b_l & \\rightarrow & b_l' = b_l-\\eta \\frac{\\partial C}{\\partial b_l} \\\\\n",
    "\\end{eqnarray}\n",
    "\\begin{align}\n",
    "\\eta = \\text{learning rate or step size}\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "![alt text](https://datascience-enthusiast.com/figures/kiank_sgd.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vsIT5MprhGis"
   },
   "source": [
    "#### Backpropagation\n",
    "Gradient descent requires the computation of partial derivatives $\\partial C / \\partial w$ and $\\partial C / \\partial b$ of the cost function C with respect to any weight w or bias b in the network. By means of the **backpropagation algorithm** those derivatives are computed efficiently.\n",
    "[Read more](http://neuralnetworksanddeeplearning.com/chap2.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-iQeajjDXCiS"
   },
   "source": [
    "## **Fashion Mnist Classification**\n",
    "Let's build a baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4071,
     "status": "ok",
     "timestamp": 1588762079160,
     "user": {
      "displayName": "Philipp Luchner",
      "photoUrl": "",
      "userId": "06440293557215660939"
     },
     "user_tz": -120
    },
    "id": "xTS0YM-sOJyf",
    "outputId": "5e739605-4550-4146-a90e-bd809119b88e"
   },
   "outputs": [],
   "source": [
    "#basic packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z33CvoON9uoF"
   },
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Fptwh8hO62p"
   },
   "outputs": [],
   "source": [
    "#1. Get the file\n",
    "data_train = pd.read_csv('train.csv')\n",
    "data_validate = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 412
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13209,
     "status": "ok",
     "timestamp": 1588762088350,
     "user": {
      "displayName": "Philipp Luchner",
      "photoUrl": "",
      "userId": "06440293557215660939"
     },
     "user_tz": -120
    },
    "id": "fhZAkdQzPHW3",
    "outputId": "7fe8ad39-1856-4147-ae82-41502c201450"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "      <td>150</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>169</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>129</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>188</td>\n",
       "      <td>216</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>86</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      6       0       0       0       0       0       0       0       1   \n",
       "1      2       0       0       0       0       0       0       1       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      3       0       0       0       0       0       0       0       0   \n",
       "4      1       0       0       0       0       0       0       0       0   \n",
       "5      2       0       0       0       0       0       0       0       0   \n",
       "6      8       0       0       0       0       0       0       0       0   \n",
       "7      4       0       0       0       0       0       0       0       0   \n",
       "8      0       0       0       0       0       0       1       3       0   \n",
       "9      7       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0     123  ...         0         0         0         0       127       150   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...       169        43         0         0         0         0   \n",
       "3       0  ...       129        37         0         0         0         0   \n",
       "4       0  ...         2         0         0         0         0         0   \n",
       "5       0  ...         4         0         0       188       216       103   \n",
       "6       0  ...         0         0         0         0         0         0   \n",
       "7       0  ...         0         0         0        57        86        63   \n",
       "8       0  ...       103        73         0         0         2         0   \n",
       "9       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0        28         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "5         0         0         0         0  \n",
       "6         0         0         0         0  \n",
       "7         0         0         0         0  \n",
       "8         0         0         0         0  \n",
       "9         0         0         0         0  \n",
       "\n",
       "[10 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2.Explore train data\n",
    "data_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>125</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>70</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>237</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>131</td>\n",
       "      <td>...</td>\n",
       "      <td>179</td>\n",
       "      <td>184</td>\n",
       "      <td>162</td>\n",
       "      <td>179</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>62</td>\n",
       "      <td>70</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
       "0          0       0       0       0       0       0       0       0       0   \n",
       "1          0       0       0       2       0       0       0       0       0   \n",
       "2          0       0       0       0       0       0       0       0       0   \n",
       "3          0       0       0       0       0       0       3       0       0   \n",
       "4          0       0       0       0       0       0       0       0       0   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "9995       0       0       0       0       0       0       0       0       0   \n",
       "9996       0       0       0       0       0       0       0       0       0   \n",
       "9997       0       0       0       0       0       2       4       3       0   \n",
       "9998       0       0       0       0       3       0       0       0      21   \n",
       "9999       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "      pixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0           0  ...         5         0         0         0         0   \n",
       "1           0  ...       125        32         3         0         0   \n",
       "2           0  ...         0         0         0         0         0   \n",
       "3           0  ...        70        38         1         0         0   \n",
       "4           0  ...         0         0         0         0         0   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "9995        0  ...        52         0         0         0         0   \n",
       "9996      120  ...         0         0         0         1         4   \n",
       "9997        0  ...         2         0         0         0       145   \n",
       "9998      131  ...       179       184       162       179        42   \n",
       "9999        0  ...         0         0         0        89        62   \n",
       "\n",
       "      pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0            0         0         0         0         0  \n",
       "1            0         0         0         0         0  \n",
       "2            0         0         0         0         0  \n",
       "3            0         0         0         0         0  \n",
       "4            0         0         0         0         0  \n",
       "...        ...       ...       ...       ...       ...  \n",
       "9995         0         0         0         0         0  \n",
       "9996         1         0         0         0         0  \n",
       "9997       237        76         0         0         0  \n",
       "9998         0         0         0         0         0  \n",
       "9999        70        57         0         0         0  \n",
       "\n",
       "[10000 rows x 784 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 412
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13190,
     "status": "ok",
     "timestamp": 1588762088352,
     "user": {
      "displayName": "Philipp Luchner",
      "photoUrl": "",
      "userId": "06440293557215660939"
     },
     "user_tz": -120
    },
    "id": "1OYj8kjVPHYj",
    "outputId": "ec09bbef-b233-4de7-948f-dfe676c051a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 785)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#explore test data\n",
    "print(data_train.shape)\n",
    "data_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = np.array(data_train, dtype = 'float32') # Damit Input Daten von Keras akzeptiert werden müssen wir sie in ein Array umwandeln \n",
    "data_validate = np.array(data_validate, dtype='float32') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(data_train[0,1:].reshape((28,28)))\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = data_train[:,1:]/255 #pixel data from 0-1 TODO -0.5?\n",
    "y_train = data_train[:,0] #label data\n",
    "\n",
    "data_submission = data_validate/255  # TODO -0.5?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(x_train[0].reshape((28,28)))\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es ist zu erkennen, dass die Pixel im Bereich zwischen 0 und 255 liegen. Für das Training auf dem Netzwerk müssen diese zwischen 0 und 1 liegen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale Grayscale ( [0,255] ) to [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\verena\\anaconda3\\envs\\challengeenv\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.countplot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape the array containing the images (28px x 28px and 1 channel)\n",
    "image_rows = 28\n",
    "image_cols = 28\n",
    "image_shape = (image_rows,image_cols,1)# 1 da schwarz weiß, bei Farbbildern 3 (r,g,b)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0],*image_shape)\n",
    "\n",
    "data_submission = data_submission.reshape(data_submission.shape[0],*image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: Use ImageDataGenerator: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split train data in train and validation set\n",
    "x_train2,x_validate2,y_train2,y_validate2 = train_test_split(x_train,y_train,test_size = 0.2,shuffle=True,random_state = 12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 28, 28, 1)\n",
      "(12000, 28, 28, 1)\n",
      "(48000,)\n",
      "(12000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train2.shape)\n",
    "print(x_validate2.shape)\n",
    "print(y_train2.shape)\n",
    "print(y_validate2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "luOE9qXFoiic"
   },
   "source": [
    "*Hint: increase the size of the training set with data augmentation*\n",
    "> https://www.tensorflow.org/tutorials/images/data_augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lzVKM7ow9yyu"
   },
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MowHNizVkp6y"
   },
   "source": [
    "#### Layers\n",
    "* `Dense(dimensionality of output , activation function)`: regular fully connected NN layer\n",
    "![alt text](http://neuralnetworksanddeeplearning.com/images/tikz41.png)\n",
    "* `Conv2D(dimensionality of output, kernel size,... , activation function)`: 2D convolution layer for spatial convolution over images\n",
    "![alt text](http://neuralnetworksanddeeplearning.com/images/tikz49.png)\n",
    "![alt text](https://anhreynolds.com/img/cnn.png)\n",
    "![alt text](https://i.ytimg.com/vi/rrOgPiqYu6s/hqdefault.jpg)\n",
    "* `MaxPool2D(pool_size)`: Max pooling operation for spatial data.\n",
    "![alt text](https://computersciencewiki.org/images/8/8a/MaxpoolSample2.png)\n",
    "* `Flatten()`: Flattens the input. Does not affect the batch size.\n",
    "\n",
    "![alt text](https://www.w3resource.com/w3r_images/numpy-manipulation-ndarray-flatten-function-image-1.png)\n",
    "\n",
    "* `Dropout(rate, ..., seed)`: Dropout consists in randomly setting a fraction rate of input units to 0 at each update during training time, which helps prevent overfitting.\n",
    "\n",
    "![alt text](http://neuralnetworksanddeeplearning.com/images/tikz31.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MvUVxXiU_IRu"
   },
   "source": [
    "Import [Keras](https://www.tensorflow.org/api_docs/python/tf/keras), a high-level API for TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.context._EagerDeviceContext at 0x198303edd80>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display tensorflow devices to check for cuda\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "import keras\n",
    "#print(device_lib.list_local_devices())\n",
    "\n",
    "# Set GPU as device\n",
    "#tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0], True)\n",
    "tf.config.set_soft_device_placement(False)\n",
    "#tf.debugging.set_log_device_placement(True)\n",
    "tf.device(\"/device:GPU:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B8Ao3wx_TAzZ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout,BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard# zur Visualisierung\n",
    "\n",
    "# Creates layers for data preprocessing -> helps with generalisation\n",
    "# TODO define seed globally\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "        tf.keras.layers.experimental.preprocessing.RandomZoom(height_factor=0.2, width_factor=None, fill_mode='reflect', interpolation='bilinear', seed=1234, fill_value=0.0),\n",
    "        #tf.keras.layers.experimental.preprocessing.RandomRotation(factor=0.25, fill_mode='reflect', interpolation='bilinear', seed=1234, fill_value=0.0),\n",
    "        #tf.keras.layers.experimental.preprocessing.RandomContrast(factor=0.2, seed=1234),\n",
    "        #tf.keras.layers.experimental.preprocessing.RandomTranslation(height_factor=0.2, width_factor=0.2, fill_mode='reflect', interpolation='bilinear', seed=1234, fill_value=0.0),\n",
    "        tf.keras.layers.experimental.preprocessing.RandomFlip(mode=\"horizontal_and_vertical\", seed=1234)\n",
    "])\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "        data_augmentation,\n",
    "        Conv2D(kernel_size=3,filters=10,activation='relu',input_shape=(28,28,1)),\n",
    "        Flatten(),\n",
    "        #....,\n",
    "        #....,\n",
    "        #....,\n",
    "        #....,\n",
    "        Dense(64,activation = 'relu'),\n",
    "        Dense(10,activation = 'softmax')  # 10 neurons for output, softmax best according to article TODO article here\n",
    "    ])\n",
    "\n",
    "# AlexNet\n",
    "alex_net = tf.keras.Sequential([\n",
    "        data_augmentation,\n",
    "        Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\", input_shape=(28,28,1)),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(3,3), strides=(2,2)),\n",
    "        Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(3,3), strides=(2,2)),\n",
    "        Flatten(),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1000, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(10, activation='softmax')  # 10 neurons for output, softmax best according to article TODO article here\n",
    "    ])\n",
    "\n",
    "vgg_16 = tf.keras.Sequential([\n",
    "        data_augmentation,\n",
    "        Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\", input_shape=(28,28,1)),\n",
    "        Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"same\"),\n",
    "        #Dropout(0.2),\n",
    "    \n",
    "        Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"same\"),\n",
    "        Dropout(0.2),\n",
    "    \n",
    "        Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"same\"),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        # Not using this VGG Layer since the image size is 28x28 instead of 227 x 227 (TODO find way to make network deeper)\n",
    "        #Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        #Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        #Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        #BatchNormalization(),\n",
    "        #MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"same\"),\n",
    "        #Dropout(0.2),\n",
    "    \n",
    "        Flatten(),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1000, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(10, activation='softmax')  # 10 neurons for output, softmax best according to article TODO article here\n",
    "    ])\n",
    "\n",
    "# Use batch normalization for faster convergance -> bigger learning rate\n",
    "vgg_16_batchnorm = tf.keras.Sequential([\n",
    "        data_augmentation,\n",
    "        Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\", input_shape=(28,28,1)),\n",
    "        Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"same\"),\n",
    "        #Dropout(0.2),\n",
    "    \n",
    "        Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"same\"),\n",
    "        #Dropout(0.2),\n",
    "    \n",
    "        Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"same\"),\n",
    "        #Dropout(0.2),\n",
    "        \n",
    "        # Not using this VGG Layer since the image size is 28x28 instead of 227 x 227 (TODO find way to make network deeper)\n",
    "        #Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        #Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        #Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        #BatchNormalization(),\n",
    "        #MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"same\"),\n",
    "        #Dropout(0.2),\n",
    "    \n",
    "        Flatten(),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1000, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(10, activation='softmax')  # 10 neurons for output, softmax best according to article TODO article here\n",
    "    ])\n",
    "vgg_19 = tf.keras.Sequential([\n",
    "        data_augmentation,\n",
    "        Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\", input_shape=(28,28,1)),\n",
    "        Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"same\"),\n",
    "    \n",
    "        Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"same\"),\n",
    "    \n",
    "        Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"same\"),\n",
    "        \n",
    "        # TODO smaller input dimensions (28 x 28 vs 227 x 227)?\n",
    "        Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"same\"),\n",
    "        \n",
    "        Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"same\"),\n",
    "    \n",
    "        Flatten(),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1000, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(10, activation='softmax')  # 10 neurons for output, softmax best according to article TODO article here\n",
    "    ])\n",
    "\n",
    "min_vgg_16 = tf.keras.Sequential([\n",
    "        data_augmentation,\n",
    "        Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\", input_shape=(28,28,1)),\n",
    "        MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"same\"),\n",
    "        #Dropout(0.2),\n",
    "    \n",
    "        Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"same\"),\n",
    "        Dropout(0.2),\n",
    "    \n",
    "        Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        # Not using this VGG Layer since the image size is 28x28 instead of 227 x 227 (TODO find way to make network deeper)\n",
    "        Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        #Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        #Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"same\"),\n",
    "        Dropout(0.2),\n",
    "    \n",
    "        Flatten(),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1000, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(10, activation='softmax')  # 10 neurons for output, softmax best according to article TODO article here\n",
    "    ])\n",
    "\n",
    "min_vgg_19 = tf.keras.Sequential([\n",
    "        data_augmentation,\n",
    "        Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\", input_shape=(28,28,1)),\n",
    "        #MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"same\"),\n",
    "        #Dropout(0.2),\n",
    "    \n",
    "        Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        #MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"same\"),\n",
    "        Dropout(0.2),\n",
    "    \n",
    "        Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"same\"),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"same\"),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        # Not using this VGG Layer since the image size is 28x28 instead of 227 x 227 (TODO find way to make network deeper)\n",
    "        Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"same\"),\n",
    "        Dropout(0.2),\n",
    "    \n",
    "        Flatten(),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1000, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(10, activation='softmax')  # 10 neurons for output, softmax best according to article TODO article here\n",
    "    ])\n",
    "\n",
    "\n",
    "training_network = \"min_vgg_16\"\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "\n",
    "if training_network == \"alex_net\":\n",
    "    model = alex_net\n",
    "elif training_network == \"min_vgg_16\":\n",
    "    model = min_vgg_16\n",
    "    batch_size = 128\n",
    "    learning_rate = 0.001\n",
    "elif training_network == \"min_vgg_19\":\n",
    "    model = min_vgg_19\n",
    "    learning_rate = 0.001\n",
    "    batch_size = 50\n",
    "elif training_network == \"vgg_16\":\n",
    "    model = vgg_16\n",
    "    batch_size = 128\n",
    "    learning_rate = 0.001\n",
    "elif training_network == \"vgg_16_batchnorm\":\n",
    "    model = vgg_16_batchnorm\n",
    "    learning_rate = 0.005\n",
    "elif training_network == \"vgg_19\":\n",
    "    model = vgg_19\n",
    "    learning_rate = 0.001\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q1Vr6mB_lKwq"
   },
   "source": [
    "*Hint: change the type, number and order of layers*\n",
    "> https://www.tensorflow.org/api_docs/python/tf/keras/layers\n",
    "\n",
    "*Hint: change the activation function*\n",
    "> https://www.tensorflow.org/api_docs/python/tf/keras/activations\n",
    "\n",
    "*Hint: prevent overfitting and speedup training by adding regularization*\n",
    "> https://www.tensorflow.org/tutorials/keras/overfit_and_underfit#strategies_to_prevent_overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uGih-c2LgbJu"
   },
   "source": [
    "Choose an optimizer and loss function for training\n",
    "Choose metric to evaluate performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u48C9WQ774n4"
   },
   "source": [
    "## Kompilieren des Modells\n",
    "Bevor das Modell für das Training bereit ist, müssen einige weitere Einstellungen vorgenommen werden. \n",
    "Diese werden während des Kompilierungsschritts des Modells hinzugefügt:\n",
    "\n",
    "Verlustfunktion - Hiermit wird gemessen, wie genau das Modell während des Trainings ist. Sie möchten diese Funktion minimieren, um das Modell in die richtige Richtung zu \"steuern\".\n",
    "\n",
    "Optimierer - Auf diese Weise wird das Modell basierend auf den angezeigten Daten und seiner Verlustfunktion aktualisiert.\n",
    "\n",
    "Metriken - Dient zum Überwachen der Trainings- und Testschritte. Im folgenden Beispiel wird die Genauigkeit verwendet , der Bruchteil der Bilder, die korrekt klassifiziert wurden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=True),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cnfqcmvZlUeP"
   },
   "source": [
    "*Hint: change the loss function*\n",
    "> https://www.tensorflow.org/api_docs/python/tf/keras/losses\n",
    "\n",
    "*Hint: change the optimization method and its parameters*\n",
    "> https://www.tensorflow.org/api_docs/python/tf/keras/optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OhJDBSzQonng"
   },
   "source": [
    "### Hyperparameter Tuning\n",
    "For [optimizing hyperparameters](https://en.wikipedia.org/wiki/Hyperparameter_optimization) such as learning rate of SGD in an efficient and non-heuristic way, use a subset of your training data as validation set and perform Grid Search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FdcLz18_p5z_"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ta8C6sWgVS4g",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "128/375 [=========>....................] - ETA: 48s - loss: 1.7310 - accuracy: 0.3182"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train2,\n",
    "    y_train2,\n",
    "    epochs=50, # use more epochs for alexnet\n",
    "    #epochs=14,\n",
    "    batch_size=batch_size,\n",
    "    verbose=1,\n",
    "    validation_data=(x_validate2,y_validate2),\n",
    "    use_multiprocessing=True,\n",
    "    workers=8\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 56715,
     "status": "ok",
     "timestamp": 1588762131976,
     "user": {
      "displayName": "Philipp Luchner",
      "photoUrl": "",
      "userId": "06440293557215660939"
     },
     "user_tz": -120
    },
    "id": "xv1ZHQDKVTNf",
    "outputId": "9ab698cd-c2ac-4b17-aeb5-f978cd63ae83"
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(x_validate2,y_validate2,verbose=0)\n",
    "print('Test Loss : {:.4f}'.format(score[0]))\n",
    "print('Test Accuracy : {:.4f}'.format(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.plot(history.history['loss'], label='Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title('Training - Loss Function')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training - Accuracy Function')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X0A6sAXubTIy"
   },
   "source": [
    "### Submission\n",
    "Submit your final notebook as **fashion_mnist_teamX.ipynb** and your predictions of the test data as a **predictions_teamX.csv**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 899,
     "status": "ok",
     "timestamp": 1588762760277,
     "user": {
      "displayName": "Philipp Luchner",
      "photoUrl": "",
      "userId": "06440293557215660939"
     },
     "user_tz": -120
    },
    "id": "GYlssBbUiqia",
    "outputId": "01aa38ae-2ae2-4a39-e7d7-22aff7ec462e"
   },
   "outputs": [],
   "source": [
    "# predict results\n",
    "results = model.predict(data_submission)\n",
    "print(results)\n",
    "# select the indix with the maximum probability\n",
    "results = np.argmax(results,axis = 1)\n",
    "\n",
    "results = pd.Series(results,name=\"Label\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.predict([data_submission[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise feature maps (from https://machinelearningmastery.com/how-to-visualize-filters-and-feature-maps-in-convolutional-neural-networks/)\n",
    "for i in range(len(model.layers)):\n",
    "    layer = model.layers[i]\n",
    "    # check for convolutional layer\n",
    "    if 'conv' not in layer.name:\n",
    "        continue\n",
    "    fm_model = tf.keras.Model(inputs=model.inputs, outputs=model.layers[i].output)\n",
    "    print(data_submission[0].shape)\n",
    "    feature_maps = fm_model.predict([data_submission[0]])\n",
    "    # plot the output from each block\n",
    "    square = 8\n",
    "    for fmap in feature_maps:\n",
    "        # plot all 64 maps in an 8x8 squares\n",
    "        ix = 1\n",
    "        for _ in range(square):\n",
    "            for _ in range(square):\n",
    "                # specify subplot and turn of axis\n",
    "                ax = plt.subplot(square, square, ix)\n",
    "                ax.set_xticks([])\n",
    "                ax.set_yticks([])\n",
    "                # plot filter channel in grayscale\n",
    "                print(fmap.shape)\n",
    "                plt.imshow(fmap[0, :, ix-1], cmap='gray')\n",
    "                ix += 1\n",
    "        # show the figure\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model to disk\n",
    "from datetime import datetime\n",
    "if True:\n",
    "    model.save(\"trained_models/model_\" + datetime.now().strftime(\"%d%m%Y_%H%M%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 550,
     "status": "ok",
     "timestamp": 1588762762823,
     "user": {
      "displayName": "Philipp Luchner",
      "photoUrl": "",
      "userId": "06440293557215660939"
     },
     "user_tz": -120
    },
    "id": "INl9cwRWi33g",
    "outputId": "27402ea0-a73a-4fb9-e306-6a776d1cb5ec"
   },
   "outputs": [],
   "source": [
    "data_results = pd.DataFrame(results)\n",
    "data_results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u9RoRppakBZk"
   },
   "outputs": [],
   "source": [
    "data_results.to_csv('fashion_mnist_pred_teamX.csv', index=False)#Bitte statt X eure Gruppennummer einfügen! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Jw6h5WYfeCr"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T4JfEh7kvx6m"
   },
   "source": [
    "## Ressources\n",
    "Background:\n",
    "  * Book: [Neural Networks and Deep Learning, Michael Nielsen](http://neuralnetworksanddeeplearning.com) \n",
    "  * Lecture: [CS231n, Stanford University](http://cs231n.stanford.edu/)\n",
    "\n",
    "Implementation:\n",
    "  * [TensorFlow tutorials](https://www.tensorflow.org/tutorials)\n",
    "  * [Keras Docs](https://www.tensorflow.org/api_docs/python/tf/keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BOkMb2Px8JOS"
   },
   "source": [
    "## Image Sources\n",
    "* http://neuralnetworksanddeeplearning.com/images/\n",
    "* https://www.researchgate.net/publication/320270458/figure/fig1/AS:551197154254848@1508427050805/Mathematical-model-of-artificial-neuron.png\n",
    "* https://www.w3resource.com/w3r_images/numpy-manipulation-ndarray-flatten-function-image-1.png\n",
    "* https://computersciencewiki.org/images/8/8a/MaxpoolSample2.png\n",
    "* https://glassboxmedicine.files.wordpress.com/2019/01/slide2.jpg?w=616\n",
    "* http://neuralnetworksanddeeplearning.com/images/valley_with_ball.png\n",
    "* https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/1200px-Logistic-curve.svg.png"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "digit_recognition_baseline_final.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/tensorflow/docs/blob/master/site/en/tutorials/quickstart/advanced.ipynb",
     "timestamp": 1587494630831
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
